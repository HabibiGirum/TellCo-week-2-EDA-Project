{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../Data/Copy of Week2_challenge_data_source(CSV).csv'  # Update this with your dataset path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Inspect the dataset\n",
    "print(data.head())\n",
    "print(data.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 handsets\n",
    "top_10_handsets = data['Handset Type'].value_counts().head(10)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=top_10_handsets.values, y=top_10_handsets.index, palette=\"viridis\")\n",
    "plt.title('Top 10 Handsets Used by Customers')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Handset Type')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 3 manufacturers\n",
    "top_3_manufacturers = data['Handset Manufacturer'].value_counts().head(3)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=top_3_manufacturers.values, y=top_3_manufacturers.index, palette=\"mako\")\n",
    "plt.title('Top 3 Handset Manufacturers')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Manufacturer')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 3 manufacturers\n",
    "top_3 = top_3_manufacturers.index\n",
    "\n",
    "# Top 5 handsets per manufacturer\n",
    "top_5_per_manufacturer = {}\n",
    "for manufacturer in top_3:\n",
    "    top_5_per_manufacturer[manufacturer] = data[data['Handset Manufacturer'] == manufacturer]['Handset Type'].value_counts().head(5)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 8))\n",
    "for manufacturer, handsets in top_5_per_manufacturer.items():\n",
    "    sns.barplot(x=handsets.values, y=handsets.index, label=manufacturer)\n",
    "\n",
    "plt.title('Top 5 Handsets per Top 3 Manufacturers')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Handset Type')\n",
    "plt.legend(title=\"Manufacturer\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate per user\n",
    "user_behavior = data.groupby('IMSI').agg({\n",
    "    'Bearer Id': 'count',                 # Number of xDR sessions\n",
    "    'Dur. (ms)': 'sum',                   # Total session duration\n",
    "    'Total DL (Bytes)': 'sum',            # Total Download\n",
    "    'Total UL (Bytes)': 'sum',            # Total Upload\n",
    "    'Social Media DL (Bytes)': 'sum',     # Social Media Download\n",
    "    'Social Media UL (Bytes)': 'sum',     # Social Media Upload\n",
    "    'Youtube DL (Bytes)': 'sum',          # YouTube Download\n",
    "    'Youtube UL (Bytes)': 'sum',          # YouTube Upload\n",
    "    'Netflix DL (Bytes)': 'sum',          # Netflix Download\n",
    "    'Netflix UL (Bytes)': 'sum',          # Netflix Upload\n",
    "    'Google DL (Bytes)': 'sum',           # Google Download\n",
    "    'Google UL (Bytes)': 'sum',           # Google Upload\n",
    "    'Email DL (Bytes)': 'sum',            # Email Download\n",
    "    'Email UL (Bytes)': 'sum',            # Email Upload\n",
    "    'Gaming DL (Bytes)': 'sum',           # Gaming Download\n",
    "    'Gaming UL (Bytes)': 'sum',           # Gaming Upload\n",
    "    'Other DL (Bytes)': 'sum',            # Other Download\n",
    "    'Other UL (Bytes)': 'sum'             # Other Upload\n",
    "}).reset_index()\n",
    "\n",
    "# Add total data volume\n",
    "user_behavior['Total Data Volume (Bytes)'] = user_behavior['Total DL (Bytes)'] + user_behavior['Total UL (Bytes)']\n",
    "print(user_behavior.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize application usage\n",
    "app_usage = user_behavior[['Social Media DL (Bytes)', 'Youtube DL (Bytes)', 'Netflix DL (Bytes)', \n",
    "                           'Google DL (Bytes)', 'Email DL (Bytes)', 'Gaming DL (Bytes)', 'Other DL (Bytes)']].sum()\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "app_usage.plot(kind='pie', autopct='%1.1f%%', startangle=140, colormap='tab10')\n",
    "plt.title('Distribution of Application Usage (Download Data)')\n",
    "plt.ylabel('')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=user_behavior, x='Total Data Volume (Bytes)', y='Dur. (ms)', alpha=0.7)\n",
    "plt.title('Session Duration vs Total Data Volume')\n",
    "plt.xlabel('Total Data Volume (Bytes)')\n",
    "plt.ylabel('Session Duration (s)')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data overview\n",
    "print(data.info())\n",
    "print(data.describe())\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values)\n",
    "\n",
    "# Treat missing values for numeric columns only\n",
    "numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "data[numeric_columns] = data[numeric_columns].fillna(data[numeric_columns].mean())\n",
    "\n",
    "# Verify no missing values remain\n",
    "print(\"Remaining Missing Values:\\n\", data.isnull().sum())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to replace outliers with the column mean\n",
    "def replace_outliers_with_mean(column):\n",
    "    Q1 = column.quantile(0.25)\n",
    "    Q3 = column.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return column.apply(lambda x: column.mean() if x < lower_bound or x > upper_bound else x)\n",
    "\n",
    "# Replace outliers for all numeric columns\n",
    "numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "data[numeric_columns] = data[numeric_columns].apply(replace_outliers_with_mean)\n",
    "\n",
    "# Verify that no extreme outliers remain\n",
    "print(data[numeric_columns].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total duration per user\n",
    "data['Total Duration (s)'] = data['Dur. (ms)'] / 1000  # Convert ms to seconds\n",
    "\n",
    "# Segment into decile classes, dropping duplicate edges\n",
    "data['Decile Class'] = pd.qcut(data['Total Duration (s)'], 10, labels=range(1, 11), duplicates=\"drop\")\n",
    "\n",
    "# Compute total data (DL + UL) per decile\n",
    "decile_summary = data.groupby('Decile Class').agg({\n",
    "    'Total DL (Bytes)': 'sum',\n",
    "    'Total UL (Bytes)': 'sum'\n",
    "})\n",
    "decile_summary['Total Data (Bytes)'] = decile_summary['Total DL (Bytes)'] + decile_summary['Total UL (Bytes)']\n",
    "\n",
    "print(decile_summary)\n",
    "\n",
    "# Ensure all necessary columns are present and numeric\n",
    "numeric_columns = ['Dur. (ms)', 'Total DL (Bytes)', 'Total UL (Bytes)']\n",
    "data[numeric_columns] = data[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Calculate total duration per user\n",
    "data['Total Duration (s)'] = data['Dur. (ms)'] / 1000  # Convert ms to seconds\n",
    "\n",
    "# Segment into decile classes, dropping duplicate edges\n",
    "data['Decile Class'] = pd.qcut(data['Total Duration (s)'], 10, labels=range(1, 11), duplicates=\"drop\")\n",
    "\n",
    "# Compute total data (DL + UL) per decile\n",
    "decile_summary = data.groupby('Decile Class').agg({\n",
    "    'Total DL (Bytes)': 'sum',\n",
    "    'Total UL (Bytes)': 'sum'\n",
    "})\n",
    "decile_summary['Total Data (Bytes)'] = decile_summary['Total DL (Bytes)'] + decile_summary['Total UL (Bytes)']\n",
    "\n",
    "print(decile_summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic metrics for quantitative variables\n",
    "metrics = data[numeric_columns].agg(['mean', 'median', 'std', 'min', 'max']).T\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship between applications and total data\n",
    "apps = ['Social Media DL (Bytes)', 'Google DL (Bytes)', 'Email DL (Bytes)',\n",
    "        'Youtube DL (Bytes)', 'Netflix DL (Bytes)', 'Gaming DL (Bytes)', 'Other DL (Bytes)']\n",
    "\n",
    "for app in apps:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.scatterplot(data=data, x=app, y='Total DL (Bytes)')\n",
    "    plt.title(f'{app} vs Total DL Data')\n",
    "    plt.xlabel(app)\n",
    "    plt.ylabel('Total DL Data')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "selected_apps = ['Social Media DL (Bytes)', 'Google DL (Bytes)', 'Email DL (Bytes)',\n",
    "                 'Youtube DL (Bytes)', 'Netflix DL (Bytes)', 'Gaming DL (Bytes)', 'Other DL (Bytes)']\n",
    "correlation_matrix = data[selected_apps].corr()\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data[selected_apps])\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=3)\n",
    "pca_result = pca.fit_transform(data_scaled)\n",
    "\n",
    "# Explained variance\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(\"Explained Variance Ratios:\", explained_variance)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
